<!DOCTYPE html>
<html lang="en">
<head>
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
	<link rel="icon" href="index_files/favicon.png" type="image/png">
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@400;500;600;700&display=swap" rel="stylesheet">
	<meta name="description" content="Refactoring Codebases through Library Design">
	<meta name="keywords" content="research, computer science">
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link href="./style.css" rel="stylesheet" type="text/css">
	<link rel="stylesheet" href="./diff-viz-styles.css">
	<title>Refactoring Codebases through Library Design</title>

	<!-- MathJax Configuration -->
	<script>
		window.MathJax = {
			tex: {
				inlineMath: [['$', '$'], ['\\(', '\\)']],
				displayMath: [['$$', '$$'], ['\\[', '\\]']],
				processEscapes: true,
				processEnvironments: true,
				macros: {
					program: '\\ensuremath{\\rho}',
					library: '\\ensuremath{\\mathcal{L}}',
					loss: ['\\ensuremath{\\ell}\\left( #1 \\right)', 1],
					sample: ['\\ensuremath{\\textsc{Sample}}\\left( #1 \\right)', 1],
					instance: 'Source'
				}
			},
			options: {
				ignoreHtmlClass: 'tex2jax_ignore',
				processHtmlClass: 'tex2jax_process'
			}
		};
	</script>
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

	<script>
		function copyText() {
			var text = document.getElementById("citation-content")
			navigator.clipboard.writeText(text.innerText)
		}
	</script>
</head>

<body>
	<header>
		<h1>Refactoring Codebases through Library Design</h1>

		<div class="authors">
			<div class="author-names">
				<span class="author-block"><a href="https://zzigak.github.io/">Žiga Kovačič</a><sup>*</sup><sup>1</sup>,</span>
				<span class="author-block"><a href="https://celine-lee.github.io/">Celine Lee</a><sup>*</sup><sup>1</sup>,</span>
				<span class="author-block"><a href="https://justinchiu.netlify.app/">Justin T Chiu</a><sup>*</sup><sup>2</sup>,</span>
				<span class="author-block"><a href="https://wenting-zhao.github.io/">Wenting Zhao</a><sup>†</sup><sup>1</sup>,</span>
				<span class="author-block"><a href="https://www.cs.cornell.edu/~ellisk/">Kevin Ellis</a><sup>†</sup><sup>1</sup></span>
			</div>
			<div class="author-affiliations">
				<span class="affiliation-block"><sup>1</sup>Cornell University,</span>
				<span class="affiliation-block"><sup>2</sup>Cohere</span>
			</div>
			<div class="author-notes" style="text-align: center; margin-top: 0.5em; font-size: 0.9em; color: #666;">
				<span><sup>*</sup> Equal contribution</span>
				<span style="margin-left: 1em;"><sup>†</sup> Equal advisorship</span>
			</div>
		</div>

		<!-- <h2>In submission at NeurIPS</h2> -->

		<nav>
			<ul>
				<li><a href="https://arxiv.org/abs/2506.11058" target="_blank" class="nav-button"><i class="ai ai-arxiv"></i> arXiv</a></li>
				<li><a href="https://github.com/code-refactor/minicode" target="_blank" class="nav-button"><i class="fa-brands fa-github"></i> Minicode</a></li>
				<li><a href="https://github.com/code-refactor/Librarian" target="_blank" class="nav-button"><i class="fa-brands fa-github"></i> Librarian</a></li>
				<li><a href="#citation" class="nav-button"><i class="fa-solid fa-quote-right"></i> Citation</a></li>
			</ul>
		</nav>

		<figure id="teaser">
			<img src="images/minicode.svg" alt="teaser">
			<figcaption style="text-align: center;">Given a collection of different code sources, where a source is either program or repository and an optional existing library, agents must refactor the code sources by designing a new modular and reusable library. Candidate refactorings are evaluated based on program simplicity (compression) across both the library and refactored sources, and are expected to maintain correctness of the original code sources (pass rate).</figcaption>
		</figure>
	</header>

	<main>
	<section>
		<h2 id="abstract">Abstract</h2>
		<p>Maintainable and general software allows developers to build robust applications efficiently, yet achieving these qualities often requires refactoring specialized solutions into reusable components. This challenge becomes particularly relevant as code agents become increasingly accurate at solving isolated programming problems. We investigate code agents' capacity to refactor code in ways supporting growth and reusability. We present both a method and a benchmark for refactoring: Librarian, a sample-and-rerank method for generating reusable libraries, and Minicode, a benchmark where code agents must minimize and refactor multiple independent solutions into a joint library. Compared to state-of-the-art code agents, Librarian achieves strong results on both compression and correctness on Minicode, obtaining compression rates 1.6-2x better than coding agents while also improving correctness. We open-source our code, benchmark, and benchmark scripting.</p>
	</section>

	<section>
		<h2 id="demo">Demo</h2>
		<figure id="demo-figure">
			<div class="demo-wrapper">
				<div class="container">
					<div class="code-panel">
						<div class="code-header" id="libraryFileName">library.py</div>
						<div class="code-content" id="libraryContent"></div>
					</div>
					<div class="code-panel">
						<div class="code-header" id="solutionFileName">solution.py</div>
						<div class="code-content" id="solutionContent"></div>
					</div>
				</div>
				<div class="status-badge">
					<span class="phase-indicator"></span>
					<span id="currentPhase">Loading...</span>
					| Timestep <span id="timestepCount">0</span>
				</div>
			</div>
			<figcaption>Librarian in action: watch as it identifies common patterns and refactors multiple code sources into shorter versions by creating a unified library with reusable components.</figcaption>
		</figure>
	</section>

	<section>
		<h2 id="contributions">Key Contributions</h2>
		<div class="contributions-grid">
			<a href="https://github.com/code-refactor/Librarian" target="_blank" class="contribution-box">
				<p><strong>Librarian</strong> is a novel sample-and-rerank method that refactors codebases into reusable libraries. It clusters code to find shared structures, samples refactorings, and ranks them by simplicity and correctness. It achieves 1.6-2x better compression than top code agents while boosting accuracy.</p>
			</a>
			<a href="https://github.com/code-refactor/minicode" target="_blank" class="contribution-box">
				<p><strong>Minicode</strong> is a benchmark for testing code agents' ability to create unified libraries from multiple code sources, such as competition coding programs and Python repositories. It requires open-ended design and large-context understanding in order to craft simple libraries.</p>
			</a>
		</div>
	</section>

	<section>
		<h2 id="project-goal">Problem Statement</h2>
		<p>We study the problem of refactoring code for better organization and efficiency. Given multiple codebases with similar functionalities, our goal is to create a unified library that captures common patterns. 
			This process should significantly reduce the total amount of code while ensuring all original functionality remains intact. 
			
		</p>
		
		<p>We evaluate refactorings based on two key principles:
		
		<ul>
			<li><strong><span class="highlight highlight-green">Correctness</span> is straightforward</strong>: Does the refactored code pass all the original tests?</li>
			<li><strong><span class="highlight highlight-blue">Simplicity</span> is more nuanced</strong>: We don't just count characters; we define simplicity using <strong class="highlight highlight-orange">Minimum Description Length (MDL)</strong>. This means we're looking for code that is not only short but also natural, elegant, and extensible—like finding the most concise yet understandable way to express an idea, rather than just the shortest, potentially unreadable, version (think "Perl Golf" where the shortest code is often incomprehensible!).</li>
		</ul>

		
		<h3>Formalization</h3>
		<p>Formally, given a set of original programs $\{\rho_n\}_{n=1}^N$, we want to find a new library $\mathcal{L}$ and refactored programs $\{\rho'_n\}_{n=1}^N$. We optimize the following objective:</p>
		
		<div class="math-display">
			$$
			\ell(\mathcal{L}, \{\rho'_n\}) =
			\begin{cases}
			  -\log p_{\text{LM}}(\mathcal{L}) + \sum_n -\log p_{\text{LM}}(\rho'_n\mid\mathcal{L}) & \forall \rho_n, \, \tau(\rho_n) \leq \tau(\rho'_n) \\
			  \infty & \text{otherwise}
			\end{cases}
			$$
		</div>
		<p style="margin-top: 1em;">
			Here, $p_{\text{LM}}(\mathcal{L})$ is the probability of the library under a language model, and $p_{\text{LM}}(\rho'_n\mid\mathcal{L})$ is the probability of the refactored program $\rho'_n$ given the library $\mathcal{L}$. The constraint $\tau(\rho_n) \leq \tau(\rho'_n)$ ensures that the refactored programs pass at least as many tests as the originals. The loss function $\ell$ thus encourages solutions that are both correct and have minimal description length, as measured by the language model.
		</p>
		<p>In simpler terms, we're looking for a library and refactored programs that pass at least as many tests as the originals, and whose combined "description length" (how hard they are to describe using a language model) is minimized. This ensures our refactored code is not only correct but also intuitively simple and well-structured.</p>
	</section>

	<section>
		<h2 id="librarian-method">Librarian: Refactoring Code to Create Libraries</h2>
		<p>
			Librarian is our method for refactoring existing code into a more organized and reusable library. By identifying common patterns and abstracting them into shared building blocks, Librarian compresses collections of programs while migrating them to use these new components—reducing overall code size and often improving functionality. The method operates on a simple sample-and-rerank framework, progressively building a library of useful functions to maximize our refactoring objective. <strong>Figure 1</strong> illustrates the overall process.
		</p>
		<p>
			Librarian operates on a simple sample-and-rerank framework to maximize our refactoring objective described above. It maintains and grows a library of useful functions as part of this objective.
		</p>
		<p>Concretely, our framework follows:</p>
		<div class="math-display">
			$$
			\mathcal{L}^\star, \left\{ \rho^\star_n \right\} = \arg\min_{\mathcal{L}, \left\{ \rho'_n \right\} \in \mathrm{Sample}(\left\{ \rho_n \right\})} 
			\ell(\mathcal{L}, \left\{ \rho'_n \right\}).
			$$
		</div>
		<h3>How It Works:</h3>
		<ul>
			<li><strong>Clustering:</strong> We group related input programs into "tuples" by having a language model summarize the code, then clustering these summaries. This focuses the language model's attention on relevant code chunks.</li>
			<li><strong>Sampling Refactorings:</strong> For each tuple, Librarian retrieves relevant existing library functions. Then, using the original code and retrieved functions as context, a language model proposes K candidate refactorings.</li>
			<li><strong>Ranking with Compression:</strong> All K candidates are evaluated. We select the refactoring that scores highest on quality and maintains (or improves) test accuracy compared to the original code. New, useful library functions from the chosen refactoring are then added to the Librarian library for future use.</li>
		</ul>
	</section>

	<section>
		<h2>The MINICODE Benchmark</h2>
		<p>
			MINICODE evaluates a <strong class="highlight highlight-blue">code agent's</strong> capability to identify abstractions across multiple implementations and design reusable <strong class="highlight highlight-orange">libraries</strong>. Agents are presented with a collection of code sources and are tasked with refactoring them into a unified library. Key desiderata for these collections are that they must be <strong class="highlight highlight-blue">compressible</strong>, containing a latent shared abstraction, and <strong class="highlight highlight-blue">verifiable</strong>, allowing functional correctness to be measured. Agents interact with the benchmark via the terminal, managing multi-package Python repositories.
		</p>
		
		<h3>CodeContests Domain</h3>
		<p>
			Sourced from the CodeContests dataset, this domain uses competitive programming problems which naturally contain shared concepts and test cases. Each collection provides multiple solutions, and the agent's task is to create a central <code>library.py</code> file that is imported by each refactored solution.
		</p>

		<h3>Repositories Domain</h3>
		<p>
			This domain features synthesized projects with controlled complexity and overlap. Using a generative process, we create collections of repositories tailored to specific use cases. Agents must extract reusable functions from across these repositories and rewrite the original source code to use a new, shared <code>common</code> subpackage.
		</p>
	
		<figure class="table-figure">
			<table class="table-styled">
				<thead>
					<tr>
						<th><strong>Domain</strong></th>
						<th><strong>Sources</strong></th>
						<th><strong>Collections</strong></th>
						<th><strong>Avg LoC</strong></th>
						<th><strong>Avg Tests</strong></th>
						<th><strong>Gen by</strong></th>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td>Code Contests</td>
						<td>300</td>
						<td>30</td>
						<td>87</td>
						<td>10</td>
						<td>Humans</td>
					</tr>
					<tr>
						<td>Small Repositories</td>
						<td>262</td>
						<td>22</td>
						<td>209</td>
						<td>12</td>
						<td>o4-mini</td>
					</tr>
					<tr>
						<td>Large Repositories</td>
						<td>20</td>
						<td>10</td>
						<td>6,433</td>
						<td>101</td>
						<td>Claude-Sonnet 3.7</td>
					</tr>
				</tbody>
			</table>
			<figcaption style="text-align: center;">Table 1: MINICODE Statistics</figcaption>
		</figure>
	
	</section>

	<!-- <section>
		<h2 id="video">Video</h2>
		<iframe height="528" src="#" title="Supplemental video" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
	</section> -->

	<section class="section" id="citation">
		<div class="container is-max-desktop content">
			<h2 id="citation-header">Citation</h2>
			<div class="citation-box">
				<button class="copy" onclick="copyText()"><i class="fa fa-clipboard"></i></button>
				<pre><code id="citation-content">@misc{kovacic2025refactoringcodebaseslibrarydesign,
      title={Refactoring Codebases through Library Design}, 
      author={Ziga Kovacic and Celine Lee and Justin Chiu and Wenting Zhao and Kevin Ellis},
      year={2025},
      eprint={2506.11058},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2506.11058}, 
}</code></pre>
			</div>
		</div>
	</section>

	<!-- <section>
		<h2 id="acknowledgments">Acknowledgments</h2>
		<p>Coming soon</p>
	</section> -->
	</main>

	<footer>
		<p class="license">This website is licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
		<p class="license">This means you are free to borrow the source code of this website, we just ask that you link back to this page in the footer. Please remember to remove the analytics code included in the header of the website which you do not want on your website.</p>
		<p class="license">This website template is inspired by <a href="https://nerfies.github.io/">Nerfies</a> and <a href="https://imaging.cs.cmu.edu/">CMU Computational Imaging Lab</a> research pages.</p>
		<p class="license">Website template from <a href="https://github.com/zzigak/research-project-website">research-project-website</a>.</p>
	</footer>
	<script src="./script.js"></script>
</body>
</html>
