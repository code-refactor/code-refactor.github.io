<!DOCTYPE html>
<html lang="en">
<head>
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
	<link rel="icon" href="index_files/favicon.png" type="image/png">
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Noto+Serif:wght@400;500;600;700&display=swap" rel="stylesheet">
	<meta name="description" content="Refactoring Codebases through Library Design">
	<meta name="keywords" content="research, computer science">
	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link href="./style.css" rel="stylesheet" type="text/css">
	<link rel="stylesheet" href="./diff-viz-styles.css">
	<link rel="stylesheet" href="./filesystem-explorer.css">
	<title>Refactoring Codebases through Library Design</title>

	<!-- MathJax Configuration -->
	<script>
		window.MathJax = {
			tex: {
				inlineMath: [['$', '$'], ['\\(', '\\)']],
				displayMath: [['$$', '$$'], ['\\[', '\\]']],
				processEscapes: true,
				processEnvironments: true,
				macros: {
					program: '\\ensuremath{\\rho}',
					library: '\\ensuremath{\\mathcal{L}}',
					loss: ['\\ensuremath{\\ell}\\left( #1 \\right)', 1],
					sample: ['\\ensuremath{\\textsc{Sample}}\\left( #1 \\right)', 1],
					instance: 'Source'
				}
			},
			options: {
				ignoreHtmlClass: 'tex2jax_ignore',
				processHtmlClass: 'tex2jax_process'
			}
		};
	</script>
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

	<script>
		function copyText() {
			var text = document.getElementById("citation-content")
			navigator.clipboard.writeText(text.innerText)
		}
	</script>
</head>

<body>
	<header>
		<h1>Refactoring Codebases through Library Design</h1>

		<div class="authors">
			<div class="author-names">
				<span class="author-block"><a href="https://zzigak.github.io/">Žiga Kovačič</a><sup>*</sup><sup>1</sup>,</span>
				<span class="author-block"><a href="https://celine-lee.github.io/">Celine Lee</a><sup>*</sup><sup>1</sup>,</span>
				<span class="author-block"><a href="https://justinchiu.netlify.app/">Justin T Chiu</a><sup>*</sup><sup>2</sup>,</span>
				<span class="author-block"><a href="https://wenting-zhao.github.io/">Wenting Zhao</a><sup>†</sup><sup>1</sup>,</span>
				<span class="author-block"><a href="https://www.cs.cornell.edu/~ellisk/">Kevin Ellis</a><sup>†</sup><sup>1</sup></span>
			</div>
			<div class="author-affiliations">
				<span class="affiliation-block"><sup>1</sup>Cornell University,</span>
				<span class="affiliation-block"><sup>2</sup>Cohere</span>
			</div>
			<div class="author-notes" style="text-align: center; margin-top: 0.5em; font-size: 0.9em; color: #666;">
				<span><sup>*</sup> Equal contribution</span>
				<span style="margin-left: 1em;"><sup>†</sup> Equal advisorship</span>
			</div>
		</div>

		<!-- <h2>In submission at NeurIPS</h2> -->

		<nav>
			<ul>
				<li><a href="https://arxiv.org/abs/2506.11058" target="_blank" class="nav-button"><i class="ai ai-arxiv"></i> arXiv</a></li>
				<li><a href="https://github.com/code-refactor/minicode" target="_blank" class="nav-button"><i class="fa-brands fa-github"></i> MiniCode</a></li>
				<li><a href="https://github.com/code-refactor/Librarian" target="_blank" class="nav-button"><i class="fa-brands fa-github"></i> Librarian</a></li>
				<li><a href="#citation" class="nav-button"><i class="fa-solid fa-quote-right"></i> Citation</a></li>
			</ul>
		</nav>

		<figure id="teaser">
			<img src="images/minicode.svg" alt="teaser">
			<figcaption style="text-align: center;">Given a collection of different code sources, where a source is either program or repository and an optional existing library, agents must refactor the code sources by designing a new modular and reusable library. Candidate refactorings are evaluated based on program simplicity (compression) across both the library and refactored sources, and are expected to maintain correctness of the original code sources (pass rate).</figcaption>
		</figure>
	</header>

	<main>
	<section>
		<h2 id="abstract">Abstract</h2>
		<p>Maintainable and general software allows developers to build robust applications efficiently, yet achieving these qualities often requires refactoring specialized solutions into reusable components. This challenge becomes particularly relevant as code agents become increasingly accurate at solving isolated programming problems. We investigate code agents' capacity to refactor code in ways supporting growth and reusability. We present both a method and a benchmark for refactoring: Librarian, a sample-and-rerank method for generating reusable libraries, and MiniCode, a benchmark where code agents must minimize and refactor multiple independent solutions into a joint library. Compared to state-of-the-art code agents, Librarian achieves strong results on both compression and correctness on MiniCode, obtaining compression rates 1.6-2x better than coding agents while also improving correctness.</p>
	</section>

	<section>
		<h2 id="demo">Demo</h2>
		<figure id="demo-figure">
			<div class="demo-wrapper">
				<div class="container">
					<div class="code-panel">
						<div class="code-header" id="libraryFileName">library.py</div>
						<div class="code-content" id="libraryContent"></div>
					</div>
					<div class="code-panel">
						<div class="code-header" id="solutionFileName">solution.py</div>
						<div class="code-content" id="solutionContent"></div>
					</div>
				</div>
				<div class="status-badge">
					<span class="phase-indicator"></span>
					<span id="currentPhase">Loading...</span>
					| Timestep <span id="timestepCount">0</span>
				</div>
			</div>
			<figcaption style="text-align: center;">Librarian refactors competition coding solutions in MiniCode: Given a collection of code solutions, Librarian identifies useful abstractions and creates a library. It then rewrites each code solution using the library.</figcaption>
		</figure>
	</section>

	<section>
		<h2 id="contributions">Key Contributions</h2>
		<div class="contributions-grid">
			<a href="https://github.com/code-refactor/Librarian" target="_blank" class="contribution-box">
				<p><strong>Librarian</strong> is a sample-and-rerank method that refactors codebases into reusable libraries. It clusters code to find shared structures, samples refactorings, and ranks them by simplicity and correctness. It achieves 1.6-2x better compression than top code agents while boosting accuracy.</p>
			</a>
			<a href="https://github.com/code-refactor/minicode" target="_blank" class="contribution-box">
				<p><strong>MiniCode</strong> is a benchmark for testing code agents' ability to create unified libraries from multiple code sources, such as competition coding programs and Python repositories. It requires open-ended design and large-context understanding in order to craft simple libraries.</p>
			</a>
		</div>
	</section>

	<section>
		<h2 id="project-goal">Problem Statement</h2>
		<p>Given multiple code sources that contain problem-
specific implementations, we evaluate whether agents can create a cohesive library that captures shared abstractions.
This library must reduce the total code size while supporting all original use cases, potentially opening
up new use cases as well by mining and formalizing latent shared abstractions.
		</p>

		<p>Libraries and refactored sources must be:

		<ol>
			<li>Correct: The refactored code passes all original tests.</li>
			<li>Simple: Elegant code is short and natural.</li>
		</ol>
		We measure correctness by ensuring refactored code passes at least as many tests as the original sources and simpleness via the <a href="https://en.wikipedia.org/wiki/Minimum_description_length">mininum description length (MDL)</a>. MDL, essentially the total log probability of all code under a model, captures both shortness and naturalness. This avoids issues of <a href="https://en.wikipedia.org/wiki/Code_golf">code golf</a>, where shortness is achieved via code obfuscation.

		<p>Formally, given a set of original programs $\{\rho_n\}_{n=1}^N$, we want to find a new library $\mathcal{L}$ and refactored programs $\{\rho'_n\}_{n=1}^N$.
        We define the pass rate $\tau(\rho_n)$ as the fraction of unit tests program $\rho_n$ passes.
        In practice we are concerned both with the case where we are refactoring several sources ($N>1$) and also the case where there is only a single large source we are refactoring ($N=1$).</p>

		<p>Refactorings are evaluated using the following objective:</p>
		
		<div class="math-display">
			$$
			\ell(\mathcal{L}, \{\rho'_n\}) =
			\begin{cases}
			  -\log p_{\text{LM}}(\mathcal{L}) + \sum_n -\log p_{\text{LM}}(\rho'_n\mid\mathcal{L}) & \forall \rho_n, \, \tau(\rho_n) \leq \tau(\rho'_n) \\
			  \infty & \text{otherwise}
			\end{cases}
			$$
		</div>
		<p style="margin-top: 1em;">
			Here, $p_{\text{LM}}(\mathcal{L})$ is the probability of the library under a language model, and $p_{\text{LM}}(\rho'_n\mid\mathcal{L})$ is the probability of the refactored program $\rho'_n$ given the library $\mathcal{L}$. The constraint $\tau(\rho_n) \leq \tau(\rho'_n)$ ensures that the refactored programs pass at least as many tests as the originals. The loss function $\ell$ thus encourages solutions that are both correct and have minimal description length, as measured by the language model.
		</p>
	</section>

	<section>
		<h2>The MiniCode Benchmark</h2>
		<p>
    		We instantiate our evaluation across three splits of varying difficulty: large repositories, small repositories, and competition coding. In each of these domains, agents must understand a collection of code sources, synthesize a set of shared abstractions into a library, then refactor the code sources using that library.
    		The refactored code and library are evaluated on correctness and simplicity.
		</p>

		<h3>Repository Split</h3>
		<p>
			We synthesize both large-scale and small-scale Python repositories by prompting LMs. In order to obtain a collection of refactorable repositories, we prompt LMs to generate ideas then synthesize repositories by generating variations of those ideas via personas. Agents must create a unified <code>common</code> library package that gets imported into the original repository packages.
		</p>

		<h3>CodeContests Split</h3>
		<p>
			Sourced from the CodeContests dataset, this domain uses competitive programming problems which naturally contain shared concepts and test cases. Each collection provides multiple solutions, and the agent's task is to create a central <code>library.py</code> file that is imported into each refactored solution.
		</p>

		<figure class="table-figure">
			<table class="table-styled">
				<thead>
					<tr>
						<th><strong>Domain</strong></th>
						<th><strong>Sources</strong></th>
						<th><strong>Collections</strong></th>
						<th><strong>Avg LoC</strong></th>
						<th><strong>Avg Tests</strong></th>
						<th><strong>Generated by</strong></th>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td>Code Contests</td>
						<td>300</td>
						<td>30</td>
						<td>87</td>
						<td>10</td>
						<td>Humans</td>
					</tr>
					<tr>
						<td>Small Repositories</td>
						<td>262</td>
						<td>22</td>
						<td>209</td>
						<td>12</td>
						<td>o4-mini</td>
					</tr>
					<tr>
						<td>Large Repositories</td>
						<td>20</td>
						<td>10</td>
						<td>6,433</td>
						<td>101</td>
						<td>Claude-Sonnet 3.7</td>
					</tr>
				</tbody>
			</table>
			<figcaption style="text-align: center;">Table 1: MiniCode statistics</figcaption>
		</figure>



    <h3>Explore a CodeContests Collection</h3>
    <p>We visualize the original code sources as presented to a code agent below. We also provide the library and refactored solutions that Claude Sonnet 3.7 created in a refactor attempt.</p>
   
    <div class="filesystem-tabs-container">
        <div class="filesystem-tabs">
            <button class="tab-button active" onclick="switchFilesystemTab('before')">Before Refactoring</button>
            <button class="tab-button" onclick="switchFilesystemTab('after')">After Refactoring</button>
        </div>
        <div id="filesystem-explorer" class="tab-content active"></div>
        <div id="filesystem-refactored" class="tab-content"></div>
    </div>

    Check out the full benchmark <a href="https://github.com/code-refactor/minicode">here</a>.

	</section>

	<section>
		<h2 id="librarian-method">Librarian: Refactoring Code to Create Libraries</h2>
		<p>
			Librarian is our method for refactoring existing code into a more organized and reusable library. By identifying common patterns and abstracting them into shared building blocks, Librarian compresses collections of programs while migrating them to use these new components—reducing overall code size and often improving functionality. The method operates on a simple sample-and-rerank framework, progressively building a library of useful functions to maximize our refactoring objective. <strong>Figure 1</strong> illustrates the overall process.
		</p>
		<p>
			Librarian operates on a simple sample-and-rerank framework to maximize our refactoring objective described above. It maintains and grows a library of useful functions as part of this objective.
		</p>
		<p>Concretely, our framework follows:</p>
		<div class="math-display">
			$$
			\mathcal{L}^\star, \left\{ \rho^\star_n \right\} = \arg\min_{\mathcal{L}, \left\{ \rho'_n \right\} \in \mathrm{Sample}(\left\{ \rho_n \right\})} 
			\ell(\mathcal{L}, \left\{ \rho'_n \right\}).
			$$
		</div>
		<h3>How It Works:</h3>
		<ul>
			<li><strong>Clustering:</strong> We group related input programs into "tuples" by having a language model summarize the code, then clustering these summaries. This focuses the language model's attention on relevant code chunks.</li>
			<li><strong>Sampling Refactorings:</strong> For each tuple, Librarian retrieves relevant existing library functions. Then, using the original code and retrieved functions as context, a language model proposes K candidate refactorings.</li>
			<li><strong>Ranking with Compression:</strong> All K candidates are evaluated. We select the refactoring that scores highest on quality and maintains (or improves) test accuracy compared to the original code. New, useful library functions from the chosen refactoring are then added to the Librarian library for future use.</li>
		</ul>

	</section>

	<section>
		<h2 id="results">Results</h2>
		<p>We present the results for the CodeContests split of MiniCode below, comparing Librarian to Sonnet and codex-mini agent baselines.</p>

		<figure class="table-figure">
			<table class="table-styled">
				<thead>
					<tr>
						<th><strong>Agent</strong></th>
						<th><strong>Pass %</strong></th>
						<th><strong>MDL</strong></th>
						<th><strong>MDL %</strong></th>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td>original</td>
						<td>82.0</td>
						<td>13346.09</td>
						<td>100.0</td>
					</tr>
					<tr>
						<td>sonnet 3.7</td>
						<td>93.9</td>
						<td>14357.77</td>
						<td>107.4</td>
					</tr>
					<tr>
						<td>sonnet 4</td>
						<td>84.4</td>
						<td>10292.62</td>
						<td>77.1</td>
					</tr>
					<tr>
						<td>codex-mini</td>
						<td>82.0</td>
						<td>11608.58</td>
						<td>86.8</td>
					</tr>
				</tbody>
			</table>
			<figcaption style="text-align: center;">Table 2: Results on the MiniCode CodeContests split</figcaption>
		</figure>

		<figure class="table-figure">
			<table class="table-styled">
				<thead>
					<tr>
						<th><strong>Metric</strong></th>
						<th><strong>Value</strong></th>
					</tr>
				</thead>
				<tbody>
					<tr>
						<td>Pass Rate</td>
						<td>90.67% ±1.88</td>
					</tr>
					<tr>
						<td>Pass Rate Improvement (over non-refactored)</td>
						<td>6.33% ±1.41</td>
					</tr>
					<tr>
						<td>MDL Ratio</td>
						<td>0.53 ±0.03</td>
					</tr>
					<tr>
						<td>Token Ratio</td>
						<td>0.66 ±0.04</td>
					</tr>
					<tr>
						<td># of Library Functions</td>
						<td>10.30 ±1.41</td>
					</tr>
					<tr>
						<td>Avg Calls per Function</td>
						<td>5.17 ±1.08</td>
					</tr>
					<tr>
						<td>% Single Use Functions</td>
						<td>38.03% ±4.88</td>
					</tr>
				</tbody>
			</table>
			<figcaption style="text-align: center;">Table 3: Refactoring results for LIBRARIAN (w/ K = 8) averaged over 10 Code Contests collections</figcaption>
		</figure>

		Check out the paper for the full CodeContests results, as well as repository results!
	</section>

	<section class="section" id="citation">
		<div class="container is-max-desktop content">
			<h2 id="citation-header">Citation</h2>
			<div class="citation-box">
				<button class="copy" onclick="copyText()"><i class="fa fa-clipboard"></i></button>
				<pre><code id="citation-content">@misc{kovacic2025refactoringcodebaseslibrarydesign,
      title={Refactoring Codebases through Library Design}, 
      author={Ziga Kovacic and Celine Lee and Justin Chiu and Wenting Zhao and Kevin Ellis},
      year={2025},
      eprint={2506.11058},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2506.11058}, 
}</code></pre>
			</div>
		</div>
	</section>

	<!-- <section>
		<h2 id="acknowledgments">Acknowledgments</h2>
		<p>Coming soon</p>
	</section> -->
	</main>

	<footer>
		<!-- <p class="license">This website is licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p> -->
		<!-- <p class="license">This means you are free to borrow the source code of this website, we just ask that you link back to this page in the footer. Please remember to remove the analytics code included in the header of the website which you do not want on your website.</p> -->
		<p class="license">Website template from <a href="https://github.com/zzigak/research-project-website">research-project-website</a>.</p>
	</footer>
	<script src="./script.js"></script>
	<script src="./filesystem-explorer.js"></script>
	<script src="./filesystem-refactored.js"></script>
	<script>
		function switchFilesystemTab(tab) {
			// Update tab buttons
			document.querySelectorAll('.tab-button').forEach(btn => btn.classList.remove('active'));
			document.querySelectorAll('.tab-content').forEach(content => content.classList.remove('active'));
			
			// Activate selected tab
			event.target.classList.add('active');
			
			if (tab === 'before') {
				document.getElementById('filesystem-explorer').classList.add('active');
			} else {
				document.getElementById('filesystem-refactored').classList.add('active');
			}
		}
	</script>
</body>
</html>
